
# Mercury

- No major changes since last meeting.
- All 34 SDElement issues are now resolved

# NLP

* Fixed channel summarizer so it will not longer include @ messages to specific users
* Fixed starlette CVE
* Fixed E2E Cypress tests
	* Using the same argument from last year
	* No frontend, so it does not apply
* All 40 SDElements issues are resolved
# Action Items

-  Create agenda for AOC visit
	- Still on for meeting on Monday @0830
	- MIT/LL will attend virtually'


# Agenda

- AgenticAI talk
	- What sort of data streams can we tap into
	- Are there other DoD programs using AgenticAI
- LargerLLMs (model throughput)
	- Air field capacity planning mentioned needing larger language models
	- Uploading mechanism and PVC
	- Llama4 - Scout
	- Hardware future
- Proprietary models (Grok, ChatGPT, Claude) GOV
	- Big push from the DoD, are we using or will it give us access to additional funds
- Team size and other MAF projects that will utilize our enterprise knowledge
- Do we want to put some suggest plugin UI mockups in front of them to get feedback
	- Emergent Situations
	- MTopic page
- What kind of AI outputs do they want going to Flyaways
- EmergentSituations v2 (now with SituationTracker™️)
- MIT/LL - 577th research  clarifications
- Prioritization of FY26 requirements
- Stress Indicators (does the AOC still want)

## Cleaned-up Agenda

1. Discussions on the source of research for NLP products and what each party has put into production. This might be a large discussion so time should be allotted accordingly.
2. Showcase of the Emergent Situations v2 work up-to-date. Since we are getting further into plugin development, should we show some mockups for the various AIML efforts (Emergent and MTopic in particular) to get feedback from the AOC?
3. Should we expect changes to team size in the next FY26. Any additions would be difficult due to the hiring freeze.
4. MIT/LL's work on Airfield Capacity Planning requires a large LLM to be in-place. We can meet this requirement given the fielded hardware, but it might cut down on the throughput of our existing features (EmergentSituations, MTopic, etc.) by an unknown amount. Is this acceptable or should we begin the discussion of more/larger hardware. The hardware that we currently have fielded in production is coming up for renewal, regardless of the larger LLM do we have the budget to continue with a dedicated hardware solution. Lastly, if a larger LLM is to be installed in production, we need to resume discussions with P1 about placing a LLM in a volume on the K8 cluster to speed up pod creation.
5. The major AIML players have begun moving toward AgenticAI and external tool calling as part of the LLM's ability to plan and complete tasks. We want to see if other DoD programs are using AgenticAI or would we be on the forefront of this research and implementation. If we want to pursue AgenticAI, then what data streams can we tap into for the LLM to use at runtime. This might need a larger LLM to support (Llama-4) based on our own experiments. 
	1. We may be able to provide a demo based on some work being done offline for Gap analysis.
	2. Might require a different instantiation approach for the LLM.
	3. Role MCP will play in NITMRE.
6. Is there any need to tap into proprietary models such as Grok, Claude, etc. There has been a lot of buzz about proprietary models coming down from the CDAO's office and we may want to be ready to respond since NITMRE has more visibility. Would this open up additional funding since some of these models are being supplied to the government as a whole (I believe Grok was given 200 million recently).
7. Do we want any additional AI outputs going to Flyaways?
	1. Either existing capabilities or roadmap items.
	2. Larger LLMs might allow for JSON output
8. Does the AOC still want us to pursue indicators of stress?
9. Ideation and prioritization of FY26 AIML objectives similar to the original AOC visit.